{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-HYsnI1FPq0",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZTTtE0oFPq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "d9805967-88de-407e-9ac4-af48674a4e07"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L4Jd-OnFPrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuration\n",
        "batch_size = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Dkl_ZTFPrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimension of the embedding vector. Two too small to get\n",
        "# any meaningful embeddings, but let's make it 2 for simple visualization\n",
        "embedding_size = 2\n",
        "num_sampled = 15    # Number of negative examples to sample."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMM2DdBIFPrJ",
        "colab_type": "text"
      },
      "source": [
        "### Input some sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lnf0xl0FPrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [\"I have something that I want to say to him\",\n",
        "            \"How are you\",\n",
        "            \"We can see many stars tonight\",\n",
        "            \"That's our house\",\n",
        "            \"sung likes cats\",\n",
        "            \"she loves dogs\",\n",
        "            \"Do you know what he has done\",\n",
        "            \"cats are great companions when they want to be\",\n",
        "            \"We need to invest in clean, renewable energy\",\n",
        "            \"women love his man\",\n",
        "            \"queen love his king\",\n",
        "            \"girl love his boy\",\n",
        "            \"The line is too long. Why don't you come back tomorrow\",\n",
        "            \"man and women roam in park\",\n",
        "            \"Does it really matter\",\n",
        "            \"dynasty king remain mortal\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqueTHWuFPrO",
        "colab_type": "text"
      },
      "source": [
        "### Convert those sentences into lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p5YaN7bFPrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentences to words and count\n",
        "words = \" \".join(sentences).split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U59bF4gIFPrU",
        "colab_type": "text"
      },
      "source": [
        "### List of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOWvsUQUFPrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19641ccd-edc3-47bb-ee04-96bd9ed82246"
      },
      "source": [
        "words"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'have',\n",
              " 'something',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'say',\n",
              " 'to',\n",
              " 'him',\n",
              " 'How',\n",
              " 'are',\n",
              " 'you',\n",
              " 'We',\n",
              " 'can',\n",
              " 'see',\n",
              " 'many',\n",
              " 'stars',\n",
              " 'tonight',\n",
              " \"That's\",\n",
              " 'our',\n",
              " 'house',\n",
              " 'sung',\n",
              " 'likes',\n",
              " 'cats',\n",
              " 'she',\n",
              " 'loves',\n",
              " 'dogs',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'he',\n",
              " 'has',\n",
              " 'done',\n",
              " 'cats',\n",
              " 'are',\n",
              " 'great',\n",
              " 'companions',\n",
              " 'when',\n",
              " 'they',\n",
              " 'want',\n",
              " 'to',\n",
              " 'be',\n",
              " 'We',\n",
              " 'need',\n",
              " 'to',\n",
              " 'invest',\n",
              " 'in',\n",
              " 'clean,',\n",
              " 'renewable',\n",
              " 'energy',\n",
              " 'women',\n",
              " 'love',\n",
              " 'his',\n",
              " 'man',\n",
              " 'queen',\n",
              " 'love',\n",
              " 'his',\n",
              " 'king',\n",
              " 'girl',\n",
              " 'love',\n",
              " 'his',\n",
              " 'boy',\n",
              " 'The',\n",
              " 'line',\n",
              " 'is',\n",
              " 'too',\n",
              " 'long.',\n",
              " 'Why',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'come',\n",
              " 'back',\n",
              " 'tomorrow',\n",
              " 'man',\n",
              " 'and',\n",
              " 'women',\n",
              " 'roam',\n",
              " 'in',\n",
              " 'park',\n",
              " 'Does',\n",
              " 'it',\n",
              " 'really',\n",
              " 'matter',\n",
              " 'dynasty',\n",
              " 'king',\n",
              " 'remain',\n",
              " 'mortal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_KRWft8FPrb",
        "colab_type": "text"
      },
      "source": [
        "### Count the occurance of each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "273RwJkfFPrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = collections.Counter(words).most_common()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9EuDG-sFPrj",
        "colab_type": "text"
      },
      "source": [
        "### Build a dictionary to lookup table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Ejso3HFPrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build dictionaries\n",
        "reverse_dictionary = [i[0] for i in count] #reverse dic, idx -> word\n",
        "dic = {w: i for i, w in enumerate(reverse_dictionary)} #dic, word -> id\n",
        "voc_size = len(dic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx3OJHQvFPrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9ae359a-3e5b-48fe-b1c1-2a025b92ad8b"
      },
      "source": [
        "reverse_dictionary"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to',\n",
              " 'you',\n",
              " 'love',\n",
              " 'his',\n",
              " 'I',\n",
              " 'want',\n",
              " 'are',\n",
              " 'We',\n",
              " 'cats',\n",
              " 'in',\n",
              " 'women',\n",
              " 'man',\n",
              " 'king',\n",
              " 'have',\n",
              " 'something',\n",
              " 'that',\n",
              " 'say',\n",
              " 'him',\n",
              " 'How',\n",
              " 'can',\n",
              " 'see',\n",
              " 'many',\n",
              " 'stars',\n",
              " 'tonight',\n",
              " \"That's\",\n",
              " 'our',\n",
              " 'house',\n",
              " 'sung',\n",
              " 'likes',\n",
              " 'she',\n",
              " 'loves',\n",
              " 'dogs',\n",
              " 'Do',\n",
              " 'know',\n",
              " 'what',\n",
              " 'he',\n",
              " 'has',\n",
              " 'done',\n",
              " 'great',\n",
              " 'companions',\n",
              " 'when',\n",
              " 'they',\n",
              " 'be',\n",
              " 'need',\n",
              " 'invest',\n",
              " 'clean,',\n",
              " 'renewable',\n",
              " 'energy',\n",
              " 'queen',\n",
              " 'girl',\n",
              " 'boy',\n",
              " 'The',\n",
              " 'line',\n",
              " 'is',\n",
              " 'too',\n",
              " 'long.',\n",
              " 'Why',\n",
              " \"don't\",\n",
              " 'come',\n",
              " 'back',\n",
              " 'tomorrow',\n",
              " 'and',\n",
              " 'roam',\n",
              " 'park',\n",
              " 'Does',\n",
              " 'it',\n",
              " 'really',\n",
              " 'matter',\n",
              " 'dynasty',\n",
              " 'remain',\n",
              " 'mortal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iue1lm6KFPrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f336a3de-9947-40ca-ff47-9d242b73d536"
      },
      "source": [
        "dic"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Do': 32,\n",
              " 'Does': 64,\n",
              " 'How': 18,\n",
              " 'I': 4,\n",
              " \"That's\": 24,\n",
              " 'The': 51,\n",
              " 'We': 7,\n",
              " 'Why': 56,\n",
              " 'and': 61,\n",
              " 'are': 6,\n",
              " 'back': 59,\n",
              " 'be': 42,\n",
              " 'boy': 50,\n",
              " 'can': 19,\n",
              " 'cats': 8,\n",
              " 'clean,': 45,\n",
              " 'come': 58,\n",
              " 'companions': 39,\n",
              " 'dogs': 31,\n",
              " \"don't\": 57,\n",
              " 'done': 37,\n",
              " 'dynasty': 68,\n",
              " 'energy': 47,\n",
              " 'girl': 49,\n",
              " 'great': 38,\n",
              " 'has': 36,\n",
              " 'have': 13,\n",
              " 'he': 35,\n",
              " 'him': 17,\n",
              " 'his': 3,\n",
              " 'house': 26,\n",
              " 'in': 9,\n",
              " 'invest': 44,\n",
              " 'is': 53,\n",
              " 'it': 65,\n",
              " 'king': 12,\n",
              " 'know': 33,\n",
              " 'likes': 28,\n",
              " 'line': 52,\n",
              " 'long.': 55,\n",
              " 'love': 2,\n",
              " 'loves': 30,\n",
              " 'man': 11,\n",
              " 'many': 21,\n",
              " 'matter': 67,\n",
              " 'mortal': 70,\n",
              " 'need': 43,\n",
              " 'our': 25,\n",
              " 'park': 63,\n",
              " 'queen': 48,\n",
              " 'really': 66,\n",
              " 'remain': 69,\n",
              " 'renewable': 46,\n",
              " 'roam': 62,\n",
              " 'say': 16,\n",
              " 'see': 20,\n",
              " 'she': 29,\n",
              " 'something': 14,\n",
              " 'stars': 22,\n",
              " 'sung': 27,\n",
              " 'that': 15,\n",
              " 'they': 41,\n",
              " 'to': 0,\n",
              " 'tomorrow': 60,\n",
              " 'tonight': 23,\n",
              " 'too': 54,\n",
              " 'want': 5,\n",
              " 'what': 34,\n",
              " 'when': 40,\n",
              " 'women': 10,\n",
              " 'you': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0n-8n2FPrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4da9714-5cbb-4c8e-c247-e7b2fac8eef3"
      },
      "source": [
        "# Make indexed word data\n",
        "data = [dic[word] for word in words]\n",
        "print('Sample data', data[:10], [reverse_dictionary[t] for t in data[:10]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample data [4, 13, 14, 15, 4, 5, 0, 16, 0, 17] ['I', 'have', 'something', 'that', 'I', 'want', 'to', 'say', 'to', 'him']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0GPNGu0FPr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "05c0c347-2361-4066-cc9f-b157f5ccbb95"
      },
      "source": [
        "# Let's make a training data for window size 1 for simplicity\n",
        "# ([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox),\n",
        "cbow_pairs = [];\n",
        "for i in range(1, len(data)-1) :\n",
        "    cbow_pairs.append([[data[i-1], data[i+1]], data[i]]);\n",
        "print('Context pairs', cbow_pairs[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context pairs [[[4, 14], 13], [[13, 15], 14], [[14, 4], 15], [[15, 5], 4], [[4, 0], 5], [[5, 16], 0], [[0, 0], 16], [[16, 17], 0], [[0, 18], 17], [[17, 6], 18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JycbyEwIFPr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7340c4ba-7368-4cad-a8c8-2738d03d99d1"
      },
      "source": [
        "# Let's make skip-gram pairs\n",
        "# (quick, the), (quick, brown), (brown, quick), (brown, fox), ...\n",
        "skip_gram_pairs = [];\n",
        "for c in cbow_pairs:\n",
        "    skip_gram_pairs.append([c[1], c[0][0]])\n",
        "    skip_gram_pairs.append([c[1], c[0][1]])\n",
        "print('skip-gram pairs', skip_gram_pairs[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skip-gram pairs [[13, 4], [13, 14], [14, 13], [14, 15], [15, 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8R2_P6GFPr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edee46a5-12ea-427e-f829-e447125c8da8"
      },
      "source": [
        "def generate_batch(size):\n",
        "    assert size < len(skip_gram_pairs)\n",
        "    x_data=[]\n",
        "    y_data = []\n",
        "    r = np.random.choice(range(len(skip_gram_pairs)), size, replace=False)\n",
        "    for i in r:\n",
        "        x_data.append(skip_gram_pairs[i][0])  # n dim\n",
        "        y_data.append([skip_gram_pairs[i][1]])  # n, 1 dim\n",
        "    return x_data, y_data\n",
        "\n",
        "# generate_batch test\n",
        "print ('Batches (x, y)', generate_batch(3))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches (x, y) ([65, 61, 66], [[64], [10], [67]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpYK9BR1FPsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "c3439c3d-52e8-4c21-eacf-3612c559cbfa"
      },
      "source": [
        "# Input data\n",
        "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "# Ops and variables pinned to the CPU because of missing GPU implementation\n",
        "with tf.device('/cpu:0'):\n",
        "    # Look up embeddings for inputs.\n",
        "    embeddings = tf.Variable(\n",
        "        tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
        "    embed = tf.nn.embedding_lookup(embeddings, train_inputs) # lookup table\n",
        "\n",
        "# Construct the variables for the NCE loss\n",
        "nce_weights = tf.Variable(\n",
        "    tf.random_uniform([voc_size, embedding_size],-1.0, 1.0))\n",
        "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
        "\n",
        "# Compute the average NCE loss for the batch.\n",
        "# This does the magic:\n",
        "#   tf.nn.nce_loss(weights, biases, inputs, labels, num_sampled, num_classes ...)\n",
        "# It automatically draws negative samples when we evaluate the loss.\n",
        "loss = tf.reduce_mean(tf.nn.nce_loss(nce_weights, nce_biases, train_labels, embed, num_sampled, voc_size))\n",
        "# Use the adam optimizer\n",
        "train_op = tf.train.AdamOptimizer(1e-1).minimize(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F89FtdE1FPsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7c8d701a-e3a1-49a5-f8d6-bf7aea255fc6"
      },
      "source": [
        "# Launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # Initializing all variables\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for step in range(100):\n",
        "        batch_inputs, batch_labels = generate_batch(batch_size)\n",
        "        _, loss_val = sess.run([train_op, loss],\n",
        "                feed_dict={train_inputs: batch_inputs, train_labels: batch_labels})\n",
        "        if step % 10 == 0:\n",
        "            print(\"Loss at \", step, loss_val) # Report the loss\n",
        "\n",
        "    # Final embeddings are ready for you to use. Need to normalize for practical use\n",
        "    trained_embeddings = embeddings.eval()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at  0 24.692923\n",
            "Loss at  10 16.292217\n",
            "Loss at  20 10.714836\n",
            "Loss at  30 9.961512\n",
            "Loss at  40 12.34342\n",
            "Loss at  50 8.3872\n",
            "Loss at  60 4.234043\n",
            "Loss at  70 4.666297\n",
            "Loss at  80 3.4948673\n",
            "Loss at  90 3.8797882\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}