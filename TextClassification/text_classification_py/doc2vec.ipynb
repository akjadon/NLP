{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec implementation with Python (& Gensim)\n",
    "- Note: This code is written in Python 3.6.1 (+Gensim 2.3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.corpus import gutenberg\n",
    "from multiprocessing import Pool\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training dataset\n",
    "- Import Shakespeare's Hamlet corpus from nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = list(gutenberg.sents('shakespeare-hamlet.txt'))   # import the corpus and convert into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of corpus:  <class 'list'>\n",
      "Length of corpus:  3106\n"
     ]
    }
   ],
   "source": [
    "print('Type of corpus: ', type(sentences))\n",
    "print('Length of corpus: ', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']']\n",
      "['Actus', 'Primus', '.']\n",
      "['Fran', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])    # title, author, and year\n",
    "print(sentences[1])\n",
    "print(sentences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "- Use re module to preprocess data\n",
    "- Convert all letters into lowercase\n",
    "- Remove punctuations, numbers, etc.\n",
    "- For the doc2vec model, input data should be in format of **iterable TaggedDocuments\"**\n",
    "    - Each TaggedDocument instance comprises **words** and **tags**\n",
    "    - Hence, each document (i.e., a sentence or paragraph) should have a unique tag which is identifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word.lower() for word in sentences[i] if re.match('^[a-zA-Z]+', word)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare']\n",
      "['actus', 'primus']\n",
      "['fran']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])    # title, author, and year\n",
    "print(sentences[1])\n",
    "print(sentences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = TaggedDocument(words = sentences[i], tags = ['sent{}'.format(i)])    # converting each sentence into a TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare'], tags=['sent0'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model\n",
    "- Create a doc2vec model and train it with Hamlet corpus\n",
    "- Key parameter description (https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "    - **documents**: training data (has to be iterable TaggedDocument instances)\n",
    "    - **size**: dimension of embedding space\n",
    "    - **dm**: DBOW if 0, distributed-memory if 1\n",
    "    - **window**: number of words accounted for each context (if the window size is 3, 3 word in the left neighorhood and 3 word in the right neighborhood are considered)\n",
    "    - **min_count**: minimum count of words to be included in the vocabulary\n",
    "    - **iter**: number of training iterations\n",
    "    - **workers**: number of worker threads to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents = sentences, dm = 1, size = 100, window = 3, min_count = 1, iter = 10, workers = Pool()._processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.init_sims(replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load model\n",
    "- doc2vec model can be saved and loaded locally\n",
    "- Doing so can reduce time to train model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('doc2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('doc2vec_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity calculation\n",
    "- Similarity between embedded words (i.e., vectors) can be computed using metrics such as cosine similarity\n",
    "- For other metrics and comparisons between them, refer to: https://github.com/taki0112/Vector_Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = model.infer_vector('sent2')    # in doc2vec, infer_vector() function is used to infer the vector embedding of a document\n",
    "v2 = model.infer_vector('sent3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seeke', 0.9795917272567749),\n",
       " ('hither', 0.9794537425041199),\n",
       " ('touching', 0.9791266918182373),\n",
       " ('spade', 0.9790579080581665),\n",
       " ('goes', 0.9789791107177734),\n",
       " ('hit', 0.9789602756500244),\n",
       " ('lose', 0.9786853790283203),\n",
       " ('countries', 0.9786409139633179),\n",
       " ('rash', 0.9785533547401428),\n",
       " ('honor', 0.978546142578125)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([v1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that computes cosine similarity between two words\n",
    "def cosine_similarity(v1, v2):\n",
    "    return 1 - spatial.distance.cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95258642555608464"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v1, v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
