{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# Building a Conversational Chatbot using Rasa and Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Issue</b>: In many cases, Clients do not want to share their data and since  majority of the avialable tools are cloud-based and provide software as a service so you can not run them internally in your environment and you need to send your data to the third party. \n",
    "\n",
    "<b>Solution</b> : With <b>RASA stack</b> an open-source customizable AI tool there is no such issue. You can build, deploy or host Rasa internally in your server or environment with complete control on it.\n",
    "\n",
    "Rasa comes up with 2 components —\n",
    "\n",
    "<b>Rasa NLU:</b> NLU deals with teaching a chatbot on how to understand user inputs.<br>\n",
    "<b>Rasa Core:</b> Deals with teaching a chatbot on how to respond to user’s query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "## Starting Jupyter Notebook with necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0_7gOmu0r3v"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "# Installations\n",
    "* Rasa NLU\n",
    "* Rasa Core\n",
    "* SpaCy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4049
    },
    "colab_type": "code",
    "id": "UsvAOHF_1dAY",
    "outputId": "f65c2c83-e7ae-46ef-e800-e43dcb854766"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "!{python} -m pip install -U rasa_core==0.9.6 rasa_nlu[spacy];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.12.0-py3-none-any.whl\n",
    "!pip install -U rasa_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "wyCva14-1gD4",
    "outputId": "642d04c1-b9ad-4ed0-fb28-ee9bef21507b"
   },
   "outputs": [],
   "source": [
    "!{python} -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Downloading the English Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "eRmnEdML3OhH",
    "outputId": "cb852307-d652-40c3-cf3d-66c54f833908"
   },
   "outputs": [],
   "source": [
    "!{python} -m spacy link en_core_web_md en --force;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHYeAA859JGq"
   },
   "source": [
    "# Importing the Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U rasa_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu"
   },
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy\n",
    "#import rasa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "# 1. Teaching the bot to understand user inputs using Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDEAOmaI9o4a"
   },
   "source": [
    "## Preparing the NLU Training Data - Defining the intent\n",
    "Intent is understanding what the user wants to say. For example — if the user says “Reserve a table at Cliff House tonight” the intent can be classified as to reserve/book the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RPxeQ1_14CjK",
    "outputId": "bfb5974f-f8ea-46b8-b8cb-9dd4479ed9cc"
   },
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello\n",
    "- hi\n",
    "- Hi\n",
    "\n",
    "## intent:fine_ask\n",
    "- I am good, how are you doing?\n",
    "- I'm fine, how are you?\n",
    "- I'm good, how are you?\n",
    "\n",
    "## intent:my_name_is\n",
    "- I am [Atul](PERSON)\n",
    "- I am [Sampriti](PERSON)\n",
    "- I'm [Prerna](PERSON)\n",
    "- im [Varun](PERSON)\n",
    "- My name is [Nikhil](PERSON)\n",
    "\n",
    "## intent:fine_normal\n",
    "- I am doing great\n",
    "- I'm doing great\n",
    "- I'm fine\n",
    "- I'm good\n",
    "\n",
    "## intent:news\n",
    "- Share some latest news around the [world](category)?\n",
    "- Share some latest news in [sports](category)?\n",
    "- What is going on in [technology](category)?\n",
    "- Tell me some news about [fashion](category)\n",
    "- Tell me some news about [business](category)\n",
    "- Tell me some news about [arts](category)\n",
    "- What is going on in [arts](category)\n",
    "- What is cooking in [food](category)\n",
    "- [movies](category)\n",
    "\n",
    "## intent:thanks\n",
    "- Thanks\n",
    "- Thank you so much\n",
    "\n",
    "## intent:bye\n",
    "- No, I am good as of now. Bye\n",
    "- Bye\n",
    "- Bbye\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceazcacn9veB"
   },
   "source": [
    "## Defining the NLU Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dF60NWhR4ID6",
    "outputId": "92946645-94fc-4450-aa41-eca8895ff83c"
   },
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"                   # loads the spacy language model\n",
    "- name: \"tokenizer_spacy\"             # splits the sentence into tokens\n",
    "- name: \"ner_crf\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_spacy\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_sklearn\"   # uses the vector representation to classify using SVM\n",
    "- name: \"ner_synonyms\"                # trains the synonyms\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "## Training the NLU Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8"
   },
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "## Evaluating the NLU model on a random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad"
   },
   "outputs": [],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"Can you share some news from around the world? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "## Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164"
   },
   "outputs": [],
   "source": [
    " from rasa_nlu.test import run_evaluation\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "# 2. Teaching the bot to respond using Rasa Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKZ63AuS-ZPV"
   },
   "source": [
    "## 1. Writing  Stories\n",
    "\n",
    "<b>stories_md</b> define the sample interaction between the user and chatbot in terms of intent and action taken by the bot. Like in the previous example bot got the intent of booking the table and entities like place and time but still, there is an entity missing — no of people and that would make the next action from the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3q1XJ5O4orY",
    "outputId": "a82511c7-b7e5-462c-c5c2-35df3cabd39a"
   },
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "## fallback\n",
    "- utter_default\n",
    "\n",
    "## greeting path 1\n",
    "* greet\n",
    "- utter_greet\n",
    "\n",
    "## my name is\n",
    "* my_name_is\n",
    "- utter_its_nice_to_meet_you\n",
    "\n",
    "## fine path 1\n",
    "* fine_normal\n",
    "- utter_help\n",
    "\n",
    "## fine path 2\n",
    "* fine_ask\n",
    "- utter_reply\n",
    "\n",
    "## news path\n",
    "* news\n",
    "- utter_ofc\n",
    "- action_get_news\n",
    "\n",
    "## thanks path 1\n",
    "* thanks\n",
    "- utter_anything_else\n",
    "\n",
    "## bye path 1\n",
    "* bye\n",
    "- utter_bye\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnD9v_CX-ePm"
   },
   "source": [
    "## 2. Defining a Domain\n",
    "### Domain(domain.yml)\n",
    "The domain consists of five key parts consisting of intents, entities, slots, actions, and templates.\n",
    "\n",
    "<b>slots:</b> Slots are basically bot’s memory. They act as a key-value store which can be used to store information the user provided (e.g their home city) as well as information gathered about the outside world (e.g. the result of a database query).\n",
    "\n",
    "<b>entity:</b> Entity is to extract the useful information from the user input. From the example above <i>“Reserve a table at Cliff House tonight”</i> the entities extracted would be place and time. Place — Cliff House and Time — tonight.\n",
    "\n",
    "<b>intent: </b> Intent is understanding what the user wants to say. For example — if the user says <i>“Reserve a table at Cliff House tonight”</i> the intent can be classified as to reserve/book the table.\n",
    "\n",
    "<b>actions:</b> Actions are bots response to user input. There are 3 kinds of actions in Rasa Core: <b>default actions, utter actions & custom actions</b>\n",
    "\n",
    "<b>templates:</b> templates define the actual text responses used by the dialogue engine. The engine will pick one random response out of all the options. Notice that <b>utter_its_nice_to_meet_you</b> uses <b>PERSON</b> slot in the response to personalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3SzQq1oy5U9T",
    "outputId": "4fde8c0d-9672-457c-cacc-0e86d3ca5c80"
   },
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "slots:\n",
    "  PERSON:\n",
    "    type: text\n",
    "\n",
    "entities:\n",
    "- category\n",
    "\n",
    "intents:\n",
    "- greet\n",
    "- fine_ask\n",
    "- fine_normal\n",
    "- news\n",
    "- thanks\n",
    "- bye\n",
    "\n",
    "actions:\n",
    "- action_restart\n",
    "- action_get_news\n",
    "- utter_greet\n",
    "- utter_reply\n",
    "- utter_help\n",
    "- utter_anything_else\n",
    "- utter_ofc\n",
    "- utter_bye\n",
    "- utter_default\n",
    "- utter_its_nice_to_meet_you\n",
    "\n",
    "templates:\n",
    "\n",
    "  utter_greet:\n",
    "    - text: Hey {PERSON}, how are you?\n",
    "    - text: Hello {PERSON}, How are you doing?\n",
    "    \n",
    "  utter_its_nice_to_meet_you:\n",
    "    - It's nice to meet you, {PERSON}.\n",
    "    - Nice to meet you, {PERSON}.\n",
    "  \n",
    "  utter_reply:\n",
    "    - text: I'm doing great. Please let me know what I can do for you.\n",
    "    - text: I'm doing great. Tell me How can I help you today?\n",
    "  utter_help:\n",
    "    - text: Great{PERSON}. How can I help you?\n",
    "    - text: Great. Tell me How can I help you?\n",
    "    - text: Great. Tell me what all news you would like to get.\n",
    "  utter_anything_else:\n",
    "    - text: No worries. Is there anything else I can help you with?\n",
    "    - text: No worries. Let me know if there is anything else I can help you with\n",
    "  utter_ofc:\n",
    "    - text: I can definitely help you. The top 5 news of the {category}\n",
    "    - text: Surely, I can help you. The top 5 news of the {category}\n",
    "  utter_bye:\n",
    "    - text: Bye and have a nice day\n",
    "    - text: Bbye and have a nice day\n",
    "  utter_default:\n",
    "    - text: I am not sure what you're aiming for\n",
    "    - text: I am sorry but I am not able to get you.\n",
    "    - text: My appologies but I am not able to get you\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policies - policiy.yml\n",
    "\n",
    "The rasa core policies decide which action to take at every step in the conversation. There are different policies to choose from, and one can include multiple policies in a single rasa core Agent. But at every turn, the policy which predicts the next action with the highest confidence is used. We have configured a basic policy <b>(policy.yml)</b> for our bot as shown below which has <b>FallbackPolicy</b> as well. The fallback policy comes in to picture when <b>‘nlu_threshold’ & ‘core_threshold’</b> meets the levels defined in the policy which means that bot is not able to understand the user message and it responds with <b>‘utter_default’</b>.\n",
    "\n",
    "<b>KerasPolicy</b> uses a neural network implemented in Keras to select the next action. The default architecture is based on an LSTM (Long Short Term Memory) model\n",
    "\n",
    "<b>MemoizationPolicy</b> memorizes the conversations in your training data. It predicts the next action with confidence 1.0 if this exact conversation exists in the training data, otherwise, it predicts ‘None’ with confidence 0.0\n",
    "\n",
    "<b>FallbackPolicy</b> invokes a fallback action if the intent recognition has confidence below nlu_threshold or if none of the dialogue policies predict action with confidence higher than core_threshold\n",
    "\n",
    "One important hyperparameter for Rasa Core policies is the <b>max_history</b>. This controls how much dialogue history the model looks at to decide which action to take next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_yml = \"\"\"\n",
    "\n",
    "policies:\n",
    "  - name: KerasPolicy\n",
    "    epochs: 1000\n",
    "  - name: FallbackPolicy\n",
    "    fallback_action_name: 'utter_default'\n",
    "    nlu_threshold: 0.1\n",
    "    core_threshold: 0.2\n",
    "  - name: MemoizationPolicy\n",
    "    max_history: 5\n",
    "    \n",
    "  - name: FormPolicy\n",
    "    \"\"\"\n",
    "%store policy_yml > policies.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROL3AYs5-iCg"
   },
   "source": [
    "## Custom Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SbmLMJa5X0E"
   },
   "outputs": [],
   "source": [
    "from rasa_core.actions import Action\n",
    "from rasa_core.events import SlotSet\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "from rasa_core_sdk import Action\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class ActionGetNewst(Action):\n",
    "\n",
    "    def name(self):\n",
    "        return 'action_get_news'\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        category = tracker.get_slot('category')\n",
    "        print(category)\n",
    "        \n",
    "        url = 'https://api.nytimes.com/svc/news/v3/content/all/{category}.json'.format(category=category)\n",
    "        params = {'api-key': \"2hq54bvFO0yWiRdY70reBU2GmusBtnwM\", 'limit': 5}\n",
    "        response = requests.get(url, params).text\n",
    "        json_data = json.loads(response)['results']\n",
    "        i = 0\n",
    "        for results in json_data:\n",
    "            i = i+1\n",
    "            message = str(i) + \".\" + results['abstract']\n",
    "            dispatcher.utter_message(message)\n",
    "        return[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "##  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXZhTaSw9SNR"
   },
   "outputs": [],
   "source": [
    "\n",
    "!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "!breq install graphviz\n",
    "\n",
    "!{python} -m pip install pygraphviz;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"stories.md\", \"story_graph.png\", max_history=2)\n",
    "Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "## Training a Dialogue Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from rasa_core import config as policy_config\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "#from rasa_core.agent import Agent\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "\n",
    "fallback = FallbackPolicy(nlu_threshold=0.1,core_threshold=0.2)\n",
    "policies = policy_config.load(\"policies.yml\")\n",
    "agent = Agent(\"domain.yml\", policies = policies)\n",
    "\n",
    "#agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "#agent = Agent('domain.yml',  policies=[MemoizationPolicy(max_history=5),KerasPolicy(epochs=100)])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "#validation_split=0.2\n",
    "\n",
    "\n",
    "# agent.train(\n",
    "#     training_data,\n",
    "#     validation_split=0.0,\n",
    "#     epochs=200\n",
    "# )\n",
    "\n",
    "agent.persist('/home/edureka/models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "# Talk to your Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817"
   },
   "outputs": [],
   "source": [
    "#Starting the Bot\n",
    "\n",
    "from rasa_core.agent import Agent\n",
    "agent = Agent.load('/home/edureka/models/dialogue', interpreter=model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c"
   },
   "outputs": [],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Conversational_Chatbot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
